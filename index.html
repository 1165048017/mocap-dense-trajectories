<!doctype html>
<html>
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="chrome=1">
    <title>Mocap-dense-trajectories by jltmtz</title>

    <link rel="stylesheet" href="stylesheets/styles.css">
    <link rel="stylesheet" href="stylesheets/pygment_trac.css">
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">
    <!--[if lt IE 9]>
    <script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->
  </head>
  <body>
    <div class="wrapper">
      <header>
        <h1>Mocap-dense-trajectories</h1>
        <p>Dense trajectories generated from mocap data.</p>

        <p class="view"><a href="https://github.com/jltmtz/mocap-dense-trajectories">View the Project on GitHub <small>jltmtz/mocap-dense-trajectories</small></a></p>


        <ul>
          <li><a href="https://github.com/jltmtz/mocap-dense-trajectories/zipball/master">Download <strong>ZIP File</strong></a></li>
          <li><a href="https://github.com/jltmtz/mocap-dense-trajectories/tarball/master">Download <strong>TAR Ball</strong></a></li>
          <li><a href="https://github.com/jltmtz/mocap-dense-trajectories">View On <strong>GitHub</strong></a></li>
        </ul>
      </header>
      <section>
        <h1>
<a name="mocap-dense-trajectories" class="anchor" href="#mocap-dense-trajectories"><span class="octicon octicon-link"></span></a>mocap-dense-trajectories</h1>

<p>This code generates dense trajectories similar to <a href="https://lear.inrialpes.fr/people/wang/dense_trajectories">those of Wang et. al</a>, [1]
but generated from mocap data, instead of video sequences. For an extended 
description visit our <a href="http://www.cs.ubc.ca/%7Ejulm/mocap-dense-trajectories/">project website</a>.</p>

<p>This code was written mainly by <a href="http://www.cs.ubc.ca/%7Eankgupta/">Ankur Gupta</a> and <a href="http://www.cs.ubc.ca/%7Ejulm/">Julieta Martinez</a>.</p>

<h2>
<a name="usage" class="anchor" href="#usage"><span class="octicon octicon-link"></span></a>Usage</h2>

<p>The input is a .bvh file. You can find the entire CMU mocap dataset converted to bvh format <a href="https://sites.google.com/a/cgspeed.com/cgspeed/motion-capture/cmu-bvh-conversion">on the internet</a>.</p>

<p>To generate trajectories from a sample file, run <code>demo_trajectory_generation</code>. To see nice visualizations of the process and some of the nuts and bolts of how this is done, run <code>demo_trajectory_generation_2</code>.</p>

<p>The main function that you want to call is <code>imocap2trajectories</code>. The output is an n-by-(7 + trajectory_length*2) matrix where each row has the following entries:</p>

<pre><code>frameNum:     The trajectory ends on this frame
mean_x:       The mean value of the x coordinates of the trajectory
mean_y:       The mean value of the y coordinates of the trajectory
var_x:        The variance of the x coordinates of the trajectory
var_y:        The variance of the y coordinates of the trajectory
length:       The length of the trajectory
scale:        This information is lost due to ortographic projection. Set to -1.
Trajectory:   2x[trajectory length] (default 30 dimension). x and y entries of the trajectory.
</code></pre>

<p>As opposed to the video dense trajectories, we obviously do not compute visual descriptors along the trajectories.</p>

<h2>
<a name="citation" class="anchor" href="#citation"><span class="octicon octicon-link"></span></a>Citation</h2>

<p>If you use this code, please cite our CVPR 14 paper:</p>

<pre><code>A. Gupta, J. Martinez, J. J. Little and R. J. Woodham. "Pose from Motion for Cross-view Action Recognition via Non-linear Circulant Temporal Encoding". In CVPR, 2014.
</code></pre>

<p>Bibtex:</p>

<pre><code>@inproceedings{gupta20143dpose,
  title={{3D Pose from Motion for Cross-view Action Recognition via Non-linear Circulant Temporal Encoding}},
  author={Gupta, Ankur and Martinez, Julieta and Little, James J. and Woodham, Robert J.},
  booktitle={CVPR},
  year={2014}
}
</code></pre>

<h2>
<a name="references" class="anchor" href="#references"><span class="octicon octicon-link"></span></a>References</h2>

<ol>
<li>Wang, Heng, et al. "Action recognition by dense trajectories." Computer Vision and Pattern Recognition (CVPR), 2011 IEEE Conference on. IEEE, 2011.</li>
<li>Katz, Sagi, Ayellet Tal, and Ronen Basri. "Direct visibility of point sets." ACM Transactions on Graphics (TOG). Vol. 26. No. 3. ACM, 2007.</li>
</ol><h2>
<a name="acknowledgements" class="anchor" href="#acknowledgements"><span class="octicon octicon-link"></span></a>Acknowledgements</h2>

<p>We include the following third-party code for user's convenience. We Thank the original authors for making their code publicly available:</p>

<ul>
<li>bvh-matlab by Will Robertson. Complete project accessible <a href="https://github.com/wspr/bvh-matlab">here</a>.</li>
<li>Hidden Point Removal by Sagi Katz. Hosted at <a href="http://www.mathworks.com/matlabcentral/fileexchange/16581-hidden-point-removal">Matlab Central</a>.</li>
</ul>
      </section>
      <footer>
        <p>This project is maintained by <a href="https://github.com/jltmtz">jltmtz</a></p>
        <p><small>Hosted on GitHub Pages &mdash; Theme by <a href="https://github.com/orderedlist">orderedlist</a></small></p>
      </footer>
    </div>
    <script src="javascripts/scale.fix.js"></script>
    
  </body>
</html>